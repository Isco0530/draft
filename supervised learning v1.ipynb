{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;warnings.simplefilter('ignore')\n",
    "#忽略警告\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "#读取iris数据 4特征，3分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()\n",
    "x=wine.data\n",
    "y=wine.target\n",
    "#读取wine数据 13特征，3分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;warnings.simplefilter('ignore')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer()\n",
    "x=breast.data\n",
    "y=breast.target\n",
    "#读取breast cancer数据 判断肿瘤良性还是恶性 30特征，2分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "x=boston.data\n",
    "y=boston.target\n",
    "#读取boston房价数据 进行回归预测 13特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=9)\n",
    "#将数据随机分割成训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1K近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "y_train_pred =knn.predict(x_train)\n",
    "print(\"test score:\"+str(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"train score:\"+str(knn.score(x_train,y_train)))\n",
    "#KNN近邻为K时进行分类\n",
    "#随着邻居个数越来越多，决策边界也越来越平滑\n",
    "#这一算法对于有很多特征的数据集，尤其是大多数取值都为0的数据集（稀疏数据集）来说效果不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scores=[]\n",
    "for k in np.arange(1,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "print(scores)\n",
    "#寻找最优K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1线性回归（普通最小二乘法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "lir = LinearRegression()\n",
    "lir.fit(x_train,y_train)\n",
    "y_pred=lir.predict(x_test)\n",
    "print(\"test score:\"+str(lir.score(x_test,y_test)))\n",
    "print(\"train score：\"+str(lir.score(x_train,y_train)))\n",
    "#线性回归进行回归预测\n",
    "#训练集和测试集分数非常接近，说明可能存在欠拟合，（特征较少13个）\n",
    "#下一步特征工程，增加特征，导致过拟合引出岭回归和lasso，控制模型复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.4用于分类的线性模型（LogisticRegression&LinearSVC）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策边界是输入的线性函数，二元线性分类器是利用直线，平面或超平面来分开两个类别的分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "lr = LogisticRegression(C=100,penalty='l1')\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred_train=lr.predict(x_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(\"train score:\" +str(lr.score(x_train,y_train)))\n",
    "print(\"test score:\" +str(lr.score(x_test,y_test)))\n",
    "#运用逻辑回归进行分类\n",
    "#默认都使用L2正则化，决定正则化强度的参数是C，C越大正则化越弱，训练集拟合效果越好，\n",
    "#C越小正则化越强，模型更强调使系数向量接近零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "SVC=LinearSVC(C=1,penalty='l2',max_iter=10000)\n",
    "SVC.fit(x_train,y_train)\n",
    "y_pred=SVC.predict(x_test)\n",
    "metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"train score:\" +str(SVC.score(x_train,y_train)))\n",
    "print(\"test score:\" +str(SVC.score(x_test,y_test)))\n",
    "#运用支持向量机进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB=GaussianNB()\n",
    "GNB.fit(x_train,y_train)\n",
    "y_pred=GNB.predict(x_test)\n",
    "metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"train score:\" +str(GNB.score(x_train,y_train)))\n",
    "print(\"test score:\" +str(GNB.score(x_test,y_test)))\n",
    "#运用朴素贝叶斯进行分类\n",
    "#它的训练速度比线性分类器更快，但泛化能力稍差\n",
    "#BernoulliNB和MultinomialNB主要用于文本数据分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(1,21),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scores=[]\n",
    "for i in np.arange(0,13):\n",
    "    bostonpd=pd.DataFrame(boston.data)\n",
    "    x=bostonpd.drop(columns=[i])\n",
    "    y=boston.target\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6, random_state=9)\n",
    "    lir=LinearRegression()\n",
    "    lir.fit(x_train,y_train)\n",
    "    y_pred=lir.predict(x_test)\n",
    "    scores.append(r2_score(y_test,y_pred))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x=pd.DataFrame(boston.data)\n",
    "y=pd.DataFrame(boston.target)\n",
    "x['13']=y\n",
    "x\n",
    "g=sns.pairplot(x, x_vars=[0,1,2], y_vars='13', size=7,aspect=0.7,kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树本质上从一层层的if/else问题中进行学习，并得出结论\n",
    "防止过拟合两种策略：预剪枝，后剪枝。scikit-learn中只实现预剪枝\n",
    "关键参数max_depth，降低训练集精度，提高测试集精度.决策树泛化性能较差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "scores=[]\n",
    "for k in np.arange(1,10):    \n",
    "    tree=DecisionTreeClassifier(random_state=4,max_depth=k)\n",
    "    tree.fit(x_train,y_train)\n",
    "    y_pred=tree.predict(x_test)\n",
    "    scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "scores\n",
    "#利用决策树进行分类,关键参数max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.feature_importances_\n",
    "#特征重要性,它都是一个介于0和1之间的数字，0表示根本没用到，1表示完美预测目标值，特征重要性求和为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5决策树集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集成式合并多个机器学习模型来构建更强大模型的方法，已证明有两种集成模型对大量分类和回归的数据集都是有效的\n",
    "两者都已决策树为基础，分别是随机森林和梯度提升决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个随机森林模型，需要确定用于构造的树的个数（n_estimators），总是越大越好，在内存和时间允许的情况下尽量多\n",
    "算法随机选择特征的一个子集，选择的特征个数由max_features控制，一般选择默认值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:1.0\n",
      "test score:0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "RFC = RandomForestClassifier(n_estimators=1000)\n",
    "RFC.fit(x_train,y_train)\n",
    "y_pred=RFC.predict(x_test)\n",
    "y_train_pred=RFC.predict(x_train)\n",
    "print(\"train score:\"+str(RFC.score(x_train,y_train)))\n",
    "print(\"test score:\"+str(RFC.score(x_test,y_test)))\n",
    "#利用随即森林进行分类，关键参数n_estimators越大越好降低过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04100348, 0.01413723, 0.03973498, 0.04797103, 0.00787902,\n",
       "       0.01402666, 0.03519794, 0.07660244, 0.00550121, 0.00436354,\n",
       "       0.01378018, 0.00493371, 0.0182348 , 0.05871739, 0.00347675,\n",
       "       0.00499628, 0.00486813, 0.00517505, 0.00382732, 0.0043913 ,\n",
       "       0.11815839, 0.01608945, 0.11940851, 0.13434135, 0.01502886,\n",
       "       0.01435909, 0.02885559, 0.12497559, 0.01132216, 0.0086426 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度提升树采用连续的方式构造树，每棵树都试图纠正前一棵树的错误\n",
    "除了预剪枝与集成中树的数量之外，梯度提升的另一个重要参数是learning_rate,用于纠正每一棵树错误的强度，较高的学习率意味着每棵树都可以做出较强的修正，这样模型更为复杂，通过增大n_estimators向集成中添加更多树，也可以增强模型复杂度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:1.0\n",
      "test score:0.9780701754385965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "GBC=GradientBoostingClassifier(n_estimators=1000,max_depth=1,learning_rate=0.1)\n",
    "GBC.fit(x_train,y_train)\n",
    "y_pred=GBC.predict(x_test)\n",
    "y_train_pred=GBC.predict(x_train)\n",
    "print(\"train score:\"+str(GBC.score(x_train,y_train)))\n",
    "print(\"test score:\"+str(GBC.score(x_test,y_test)))\n",
    "#利用梯度提升机进行分类，关键参数n_estimator,max_depth,learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.46147636e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.44901282e-05, 1.86371235e-04, 0.00000000e+00, 8.22861417e-02,\n",
       "       1.02561463e-03, 1.68543381e-04, 1.53192646e-04, 1.52756103e-04,\n",
       "       0.00000000e+00, 2.04232460e-02, 7.47191471e-04, 9.39294283e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.55775489e-03,\n",
       "       0.00000000e+00, 1.34992294e-02, 1.91974012e-01, 3.69772152e-01,\n",
       "       1.24805071e-02, 5.59150978e-05, 1.02714441e-02, 2.77522188e-01,\n",
       "       1.15458244e-03, 9.60609675e-04])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.feature_importances_\n",
    "#梯度提升树的特征重要性与随机森林的特征重要性有些类似，不过梯度提升树完全忽略了某些特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6核支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核支持向量机（添加更多的非线性特征，对输入特征进行扩展），将数据映射到高维空间中主要使用径向基函数也称高斯核，\n",
    "考虑所有阶数所有可能的多项式，阶数越高特征重要性越小\n",
    "SVM关键参数gamma控制高斯核的宽度，c是正则化参数限制每个点的重要性\n",
    "为SVM预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma较小，高斯核半径越大，许多点都被看作比较靠近，决策边界变化慢，生成的是复杂度较低的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:1.0\n",
      "test score:0.6271929824561403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "svm=SVC(kernel='rbf')\n",
    "svm.fit(x_train,y_train)\n",
    "y_pred=svm.predict(x_test)\n",
    "y_train_pred=svm.predict(x_train)\n",
    "print(\"train score:\"+str(svm.score(x_train,y_train)))\n",
    "print(\"test score:\"+str(svm.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型存在相当严重过拟合，模型对参数设定和数据的缩放非常敏感，要求所有的特征有相似的变化范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9442815249266863\n",
      "test score:0.9605263157894737\n"
     ]
    }
   ],
   "source": [
    "#为SVM预处理数据,对所有特征进行缩放到0和1之间\n",
    "min_on_train=x_train.min(axis=0)\n",
    "range_on_train=(x_train-min_on_train).max(axis=0)\n",
    "x_train_scaled=(x_train-min_on_train)/range_on_train\n",
    "#训练集数据进行缩放\n",
    "min_on_test=x_test.min(axis=0)\n",
    "range_on_test=(x_test-min_on_test).max(axis=0)\n",
    "x_test_scaled=(x_test-min_on_test)/range_on_test\n",
    "#测试集数据进行缩放\n",
    "svm.fit(x_train_scaled,y_train)\n",
    "y_pred=svm.predict(x_test_scaled)\n",
    "y_train_pred=svm.predict(x_train_scaled)\n",
    "print(\"train score:\"+str(svm.score(x_train_scaled,y_train)))\n",
    "print(\"test score:\"+str(svm.score(x_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9824046920821115\n",
      "test score:0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#尝试增大c和gamma来拟合更复杂模型\n",
    "svm=SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "svm.fit(x_train_scaled,y_train)\n",
    "y_pred=svm.predict(x_test_scaled)\n",
    "y_train_pred=svm.predict(x_train_scaled)\n",
    "print(\"train score:\"+str(svm.score(x_train_scaled,y_train)))\n",
    "print(\"test score:\"+str(svm.score(x_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7神经网络（深度学习）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算完每个隐单元的加权求和之后，对结果再应用一个非线性函数-通常是校正非线性或正切双曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "控制神经网络复杂度的方法有很多种：隐层个数，每个隐层中的单元个数，正则化\n",
    "如何学习模型或用来学习参数的算法，这一点由solver参数设定，包含adam,lbfgs,sgd,使用MLP时建议使用前两种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9208211143695014\n",
      "test score:0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "#神经网络（多层感知机）Multilayer perceptron，也被称为前馈神经网络\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier(random_state=42)\n",
    "mlp.fit(x_train,y_train)\n",
    "y_pred=mlp.predict(x_test)\n",
    "y_train_pred=mlp.predict(x_train)\n",
    "print(\"train score:\"+str(mlp.score(x_train,y_train)))\n",
    "print(\"test score:\"+str(mlp.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9941348973607038\n",
      "test score:0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "#对数据进行缩放，均值为0方差为1\n",
    "mean_on_train=x_train.mean(axis=0)\n",
    "std_on_train=x_train.std(axis=0)\n",
    "x_train_scaled=(x_train-mean_on_train)/std_on_train\n",
    "#训练集数据缩放\n",
    "mean_on_test=x_test.mean(axis=0)\n",
    "std_on_test=x_test.std(axis=0)\n",
    "x_test_scaled=(x_test-mean_on_test)/std_on_test\n",
    "#测试集数据缩放\n",
    "mlp=MLPClassifier(random_state=0,max_iter=400,alpha=0.1)#警告超过最大迭代次数200，调整max_iter\n",
    "#调整alpha增强泛化性能\n",
    "mlp.fit(x_train_scaled,y_train)\n",
    "y_pred=mlp.predict(x_test_scaled)\n",
    "y_train_pred=mlp.predict(x_train_scaled)\n",
    "print(\"train score:\"+str(mlp.score(x_train_scaled,y_train)))\n",
    "print(\"test score:\"+str(mlp.score(x_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实例应用：根据M2，GDP，CPI预测不良贷款率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "data=pd.read_excel('icaap data raw.xls',sheet_name='Sheet2')\n",
    "for i in np.arange(0,136):\n",
    "    if i%3==0:\n",
    "        pass\n",
    "    elif i%3==1:\n",
    "        data.iloc[i,2]=data.iloc[i-1,2]+(data.iloc[i+2,2]-data.iloc[i-1,2])/3\n",
    "        data.iloc[i,4]=data.iloc[i-1,4]+(data.iloc[i+2,4]-data.iloc[i-1,4])/3\n",
    "    else:\n",
    "        data.iloc[i,2]=data.iloc[i-2,2]+(data.iloc[i+1,2]-data.iloc[i-2,2])/3*2\n",
    "        data.iloc[i,4]=data.iloc[i-2,4]+(data.iloc[i+1,4]-data.iloc[i-2,4])/3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,1:4]\n",
    "y=data.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:0.9819752282736258\n",
      "test score:0.9550003560191779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR=GradientBoostingRegressor(n_estimators=1000,max_depth=4,learning_rate=0.1)\n",
    "GBR.fit(x_train,y_train)\n",
    "print(\"train score:\"+str(GBR.score(x_train,y_train)))\n",
    "print(\"test score:\"+str(GBR.score(x_test,y_test)))\n",
    "#利用梯度提升机进行分类，关键参数n_estimator,max_depth,learning_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
